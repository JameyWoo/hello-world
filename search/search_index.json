{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"\u4e3b\u9875"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"Introduction to PyTorch/","text":"Introduction to PyTorch \u7b14\u8bb0 Part 1 - Tensors in PyTorch (Solution).ipynb \u6700\u57fa\u672c\u7684\u795e\u7ecf\u7f51\u7edc, \u4f7f\u7528\u77e9\u9635\u8ba1\u7b97. \u6fc0\u6d3b\u51fd\u6570, sigmoid, softmax, relu\u7b49 \u4f7f\u7528pytorch\u751f\u6210\u968f\u673a\u6570(\u7528\u6765\u521d\u59cb\u5316weights). \u4f3c\u4e4e\u7528\u4e0d\u540c\u7684norm\u51fd\u6570\u5f71\u54cd\u8f83\u5927 \u4ecb\u7ecd\u4e86\u524d\u5411\u4f20\u64ad\u7684\u5b9e\u73b0\u65b9\u5f0f, \u77e9\u9635\u76f8\u4e58 + \u504f\u7f6e \u77e9\u9635\u6539\u53d8\u5f62\u72b6, \u4ecenumpy\u8f6c\u5316\u6765/\u53bb Part 2 - Neural Networks in PyTorch (Exercises).ipynb \u52a0\u8f7dMNIST\u6570\u636e\u96c6, \u8bbe\u7f6e\u662f\u8bad\u7ec3\u6216\u8005\u6d4b\u8bd5, \u7528DataLoader\u8fdb\u884c\u5206\u6279\u52a0\u8f7d, \u53ef\u8bbe\u7f6e\u968f\u673a\u5316 \u4f7f\u7528\u4e86transforms\u8f6c\u6362\u5668\u8f6c\u6362\u6570\u636e, \u6bd4\u5982\u5f52\u4e00\u5316, \u8f6c\u5316\u4e3atensor, \u6539\u53d8\u56fe\u7247\u5927\u5c0f\u7b49 python train_transforms = transforms.Compose([transforms.RandomRotation(30), transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]) \u7ec3\u4e60\u81ea\u5b9a\u4e49\u7f51\u7edc\u6743\u91cd, \u5e76\u5b9e\u73b0\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad \u81ea\u5df1\u7528pytorch\u5b9e\u73b0\u4e86softmax. \u4f7f\u7528sum, argmax\u7b49\u51fd\u6570\u9700\u8981\u6ce8\u610f\u8bbe\u7f6edim python def softmax(x): return torch.exp(out) / torch.exp(out).sum(dim=1).view(64, 1) \u81ea\u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784(class\u65b9\u5f0f), \u7ee7\u627f\u81eann.Module. \u81ea\u5b9a\u4e49\u5c42\u6b21, \u6fc0\u6d3b\u51fd\u6570\u7b49, \u5b9e\u73b0init, forward\u51fd\u6570 ```py class Network(nn.Module): def init (self): super(). init () # Inputs to hidden layer linear transformation self.hidden = nn.Linear(784, 256) # Output layer, 10 units - one for each digit self.output = nn.Linear(256, 10) # Define sigmoid activation and softmax output self.sigmoid = nn.Sigmoid() self.softmax = nn.Softmax(dim=1) def forward(self, x): # Pass the input tensor through each of our operations x = self.hidden(x) x = self.sigmoid(x) x = self.output(x) x = self.softmax(x) return x ``` \u6709model\u5bf9\u8c61, \u53ef\u65b9\u4fbf\u5730\u67e5\u770b\u6a21\u578b\u7684\u6743\u91cd, \u504f\u7f6e\u503c, \u8fd8\u53ef\u4ee5\u8fdb\u884c\u66f4\u6539, \u5982\u4f7f\u7528\u968f\u673a\u503c \u4f7f\u7528nn.Sequential()\u642d\u5efa\u7f51\u7edc, \u548c\u4e4b\u524d\u5176\u5b9e\u7c7b\u4f3c py model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), nn.ReLU(), nn.Linear(hidden_sizes[0], hidden_sizes[1]), nn.ReLU(), nn.Linear(hidden_sizes[1], output_size), nn.Softmax(dim=1)) \u591a\u6b21\u51fa\u73b0helper\u8f85\u52a9\u4ee3\u7801, \u5b9e\u73b0\u4e00\u4e9b\u529f\u80fd, \u5982\u4e0b\u6240\u793a import matplotlib.pyplot as plt import numpy as np from torch import nn, optim from torch.autograd import Variable def test_network(net, trainloader): criterion = nn.MSELoss() optimizer = optim.Adam(net.parameters(), lr=0.001) dataiter = iter(trainloader) images, labels = dataiter.next() # Create Variables for the inputs and targets inputs = Variable(images) targets = Variable(images) # Clear the gradients from all Variables optimizer.zero_grad() # Forward pass, then backward pass, then update weights output = net.forward(inputs) loss = criterion(output, targets) loss.backward() optimizer.step() return True def imshow(image, ax=None, title=None, normalize=True): \"\"\"Imshow for Tensor.\"\"\" if ax is None: fig, ax = plt.subplots() image = image.numpy().transpose((1, 2, 0)) if normalize: mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) image = std * image + mean image = np.clip(image, 0, 1) ax.imshow(image) ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False) ax.spines['bottom'].set_visible(False) ax.tick_params(axis='both', length=0) ax.set_xticklabels('') ax.set_yticklabels('') return ax def view_recon(img, recon): ''' Function for displaying an image (as a PyTorch Tensor) and its reconstruction also a PyTorch Tensor ''' fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True) axes[0].imshow(img.numpy().squeeze()) axes[1].imshow(recon.data.numpy().squeeze()) for ax in axes: ax.axis('off') ax.set_adjustable('box-forced') def view_classify(img, ps, version=\"MNIST\"): ''' Function for viewing an image and it's predicted classes. ''' ps = ps.data.numpy().squeeze() fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2) ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze()) ax1.axis('off') ax2.barh(np.arange(10), ps) ax2.set_aspect(0.1) ax2.set_yticks(np.arange(10)) if version == \"MNIST\": ax2.set_yticklabels(np.arange(10)) elif version == \"Fashion\": ax2.set_yticklabels(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot'], size='small'); ax2.set_title('Class Probability') ax2.set_xlim(0, 1.1) plt.tight_layout() Part 3 - Training Neural Networks (Exercises).ipynb \u68af\u5ea6\u4e0b\u964d\u4e0e\u53cd\u5411\u4f20\u64ad. \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u662f\u6c42\u5bfc\u8fc7\u7a0b\u4e2d\u94fe\u5f0f\u6cd5\u5219\u7684\u5e94\u7528 $$ \\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2} $$ $$ \\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1} $$ \u901a\u5e38\u4f1a\u5bfc\u5165\u7684\u5305 py import torch from torch import nn import torch.nn.functional as F from torchvision import datasets, transforms \u4ecb\u7ecd\u4e86\u635f\u5931\u51fd\u6570. \u6bd4\u5982\u4ea4\u53c9\u71b5nn.CrossEntropyLoss(), \u4e00\u822c\u8d4b\u503c\u7ed9criterion \u8fd8\u6709\u6bd4\u5982nn.NLLLoss() \u4ecb\u7ecd\u4e86\u81ea\u52a8\u6c42\u5bfcautograd, \u8c03\u7528.backward()\u53ef\u67e5\u770b\u5bfc\u6570 \u4ecb\u7ecd\u4e86optimizer, \u5728torch.optim\u4e2d. \u6709SGD(\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b49). Adam\u66f4\u597d. ```py from torch import optim Optimizers require the parameters to optimize and a learning rate optimizer = optim.SGD(model.parameters(), lr=0.01) ``` \u8bad\u7ec3\u4e2d\u8bb0\u5f97\u6e05\u96f6\u68af\u5ea6 optimizer.zero_grad() optimizer\u8c03\u7528step()\u65b9\u6cd5\u66f4\u65b0\u6a21\u578b\u7684\u6743\u91cd \u4e00\u4e2a\u8f83\u5b8c\u6574\u7684\u8bad\u7ec3\u8fc7\u7a0b ```py Your solution here model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10), nn.LogSoftmax(dim=1)) criterion = nn.NLLLoss() optimizer = optim.SGD(model.parameters(), lr=0.003) epochs = 5 for e in range(epochs): running_loss = 0 for images, labels in trainloader: # Flatten MNIST images into a 784 long vector images = images.view(images.shape[0], -1) # TODO: Training pass optimizer.zero_grad() output = model.forward(images) print(output.shape) print(labels.shape) loss = criterion(output, labels) running_loss += loss.item() loss.backward() optimizer.step() else: print(f\"Training loss: {running_loss/len(trainloader)}\") ``` Part 4 - Fashion-MNIST (Exercises).ipynb \u4f7f\u7528pytorch\u5bf9\u6570\u636e\u96c6Fashion-MNIST\u8fdb\u884c\u5206\u7c7b\u7684\u7ec3\u4e60, \u6709\u5982\u4e0b\u8fc7\u7a0b \u5bfc\u5165\u5fc5\u8981\u7684\u5e93 \u5bfc\u5165\u6570\u636e\u96c6\u5e76\u683c\u5f0f\u5316 \u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784 \u5b9a\u4e49optimizer, loss\u51fd\u6570\u7b49 \u5f00\u59cb\u8bad\u7ec3, \u5206epoch\u548cbatch \u524d\u5411\u4f20\u64ad\u540e\u8ba1\u7b97\u635f\u5931\u51fd\u6570, \u6c42\u68af\u5ea6, \u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u6743\u91cd \u8bad\u7ec3\u7ed3\u675f, \u8f93\u51fa\u6b63\u786e\u7387, \u635f\u5931\u503c\u7b49\u7b49 \u5b8c\u6574\u4ee3\u7801\u5982\u4e0b ```pyimport torch import torch.nn.functional as F from torch import nn, optim from torchvision import datasets, transforms Define a transform to normalize the data transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) Download and load the training data trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) Download and load the test data testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True) \u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784 class MyFashionMnist(nn.Module): def init (self): super(). init () self.fc1 = nn.Linear(784, 256) self.fc2 = nn.Linear(256, 64) self.fc3 = nn.Linear(64, 10) def forward(self, x): x = x.view(-1, 784) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = F.log_softmax(self.fc3(x)) return x model = MyFashionMnist() optimizer = optim.Adam(model.parameters(), lr=0.003) criterion = nn.NLLLoss() epochs = 20 for e in range(epochs): running_loss = 0 # \u635f\u5931 for images, labels in trainloader: output = model(images) loss = criterion(output, labels) optimizer.zero_grad() loss.backward() optimizer.step() running_loss += loss.item() else: print(\"loss: \", running_loss / len(trainloader)) sum = correct = 0 \u7528\u6d4b\u8bd5\u96c6\u6d4b\u8bd5\u6b63\u786e\u7387 for images, labels in testloader: output = torch.exp(model(images)) result = torch.argmax(output, dim=1) correct += (result == labels).sum() sum += len(images) print(\"correct = \", correct.item()) print(\"sum = \", sum) print(\"rate = {}\".format(correct.item() / sum)) \u5199\u4e86\u4e00\u4efd\u57fa\u4e8ekeras\u7684\u4ee3\u7801\u505a\u5bf9\u6bd4, \u8fc7\u7a0b\u662f\u7c7b\u4f3c\u7684. \u76f8\u5bf9\u800c\u8a00keras\u66f4\u9ed1\u7bb1\u6240\u4ee5\u4ee3\u7801\u77ed\u4e00\u4e9b ```py import tensorflow as tf from tensorflow.keras import datasets, models, layers import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' (train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data() train_images = tf.reshape(train_images, [-1, 784]) test_images = tf.reshape(test_images, [-1, 784]) print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape) model = models.Sequential() model.add(layers.Dense(256, activation='relu', input_shape=(784, ))) model.add(layers.Dense(64, activation='relu')) model.add(layers.Dense(10, activation='softmax')) print(\"model build!\") model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) # \u5c06\u8bad\u7ec3\u96c6\u968f\u673a\u5316 idx = tf.range(len(train_images)) idx = tf.random.shuffle(idx) print(idx) train_images = tf.gather(train_images, indices=idx) # train_images = train_images[idx] train_labels = tf.gather(train_labels, indices=idx) # train_labels = train_labels[idx] # \u5c06label\u8f6c\u5316\u6210one hot train_labels = tf.one_hot(train_labels, depth=10) test_labels = tf.one_hot(test_labels, depth=10) # \u5212\u5206\u51fa\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 partial_x_train = train_images[3000:] x_val = train_images[:3000] partial_y_train = train_labels[3000:] y_val = train_labels[:3000] print(partial_x_train.shape, partial_y_train.shape, x_val.shape, y_val.shape) history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=64, validation_data=(x_val, y_val)) result = model.evaluate(test_images, test_labels) \u5dee\u522b\u662f: keras\u7684\u8bad\u7ec3\u8d77\u6765\u8981\u6bd4pytorch\u5feb\u5f97\u591a. \u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u56e0\u4e3akeras\u5728gpu\u6761\u4ef6\u6ee1\u8db3\u60c5\u51b5\u4e0b\u81ea\u52a8\u8c03\u7528\u4e86gpu, \u800cpytorch\u7528\u7684\u662fcpu \u51c6\u786e\u7387\u7528pytorch\u5199\u7684\u53cd\u800c\u8981\u9ad8, \u8fd9\u4e48\u4e00\u4e2a\u7b80\u5355\u7684\u7f51\u7edc\u6b63\u786e\u7387\u8fbe\u5230\u4e8686%-87%, \u800c\u53cd\u89c2keras\u7684, \u5728\u548cpytorch\u7684\u8d85\u53c2\u6570\u5dee\u4e0d\u591a\u7684\u60c5\u51b5\u4e0b, \u6b63\u786e\u7387\u53ea\u670970%\u5de6\u53f3. \u8bbe\u7f6e\u5176\u4ed6\u7684\u8d85\u53c2\u6570\u624d\u80fd\u7a0d\u9ad8\u4e00\u4e9b Part 5 - Inference and Validation (Exercises).ipynb \u8fd9\u90e8\u5206\u4e3b\u8981\u8bb2\u9a8c\u8bc1, \u6bd4\u5982\u7528topk()\u6765\u8861\u91cf\u6b63\u786e \u4f46\u7528topk()\u65f6\u603b\u662f\u51fa\u9519, \u6240\u4ee5\u540e\u9762\u6539\u7528argmax()\u4e86 \u4ecb\u7ecd\u4e86dropout\u7684\u4f7f\u7528, \u53ef\u4ee5\u660e\u663e\u5730\u51cf\u5c11\u8fc7\u62df\u5408. \u4e5f\u5c31\u662f\u8bad\u7ec3\u65f6\u7684\u635f\u5931\u548c\u9a8c\u8bc1\u635f\u5931\u5dee\u4e0d\u591a, \u4f46\u540c\u65f6\u8bad\u7ec3\u65f6\u6b63\u786e\u7387\u66f4\u4f4e\u4e00\u4e9b dropout\u4e5f\u771f\u662f\u7384\u5b66 \u5b9a\u4e49\u4e86\u81ea\u5df1\u7684\u5e26dropout\u5c42\u7684\u7f51\u7edc ```py TODO: Define your model with dropout added from torch import nn, optim import torch.nn.functional as F class Classifier(nn.Module): def init (self): super(). init () self.fc1 = nn.Linear(784, 256) self.fc2 = nn.Linear(256, 128) self.fc3 = nn.Linear(128, 64) self.fc4 = nn.Linear(64, 10) self.dropout = nn.Dropout(p=0.2) def forward(self, x): # make sure input tensor is flattened x = x.view(x.shape[0], -1) x = self.dropout(F.relu(self.fc1(x))) x = self.dropout(F.relu(self.fc2(x))) x = self.dropout(F.relu(self.fc3(x))) x = F.log_softmax(self.fc4(x), dim=1) return x ``` \u5728\u8bad\u7ec3\u65f6\u8bb0\u5f55\u4e86\u5404\u4e2a\u65f6\u95f4\u70b9\u7684\u635f\u5931, \u6240\u4ee5\u7528\u4e0b\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u8f7b\u677e\u753b\u51fa\u635f\u5931\u7684\u53d8\u5316\u503c, \u6765\u5224\u65ad\u662f\u5426\u53d1\u751f\u8fc7\u62df\u5408 ```py import matplotlib.pyplot as plt train_losses = torch.Tensor(train_losses) / len(trainloader) test_losses = torch.Tensor(test_losses) / len(testloader) plt.plot(train_losses.numpy(), label='train_losses') plt.plot(test_losses.numpy(), label='test_losses') plt.legend() ``` \u5728\u9a8c\u8bc1\u65f6\u9700\u8981\u8c03\u7528model.eval(), \u907f\u514d\u9a8c\u8bc1\u8fdb\u5165dropout. \u8bad\u7ec3\u65f6\u8981\u9a8c\u8bc1, \u9a8c\u8bc1\u4e4b\u540e\u8981\u7528model.train()\u8fdb\u5165\u8bad\u7ec3\u6a21\u5f0f Part 6 - Saving and Loading Models.ipynb \u8fd9\u90e8\u5206\u5c06\u5982\u4f55\u4fdd\u5b58\u548c\u6062\u590d\u6a21\u578b, \u56e0\u4e3a\u8fd9\u4e00\u8282notebook\u8fd0\u884c\u8f83\u9ebb\u70e6\u539f\u56e0\u6ca1\u6709\u5f88\u8ba4\u771f\u53bb\u770b... Part 7 - Loading Image Data (Exercises).ipynb \u8fd9\u90e8\u5206\u8bb2\u5982\u4f55\u4ece\u6587\u4ef6\u5939\u4e2d\u52a0\u8f7d\u6570\u636e\u96c6 \u6587\u4ef6\u5939\u683c\u5f0f, \u4e3b\u6587\u4ef6\u5939\u4e0b\u6709\u591a\u4e2a\u5b50\u6587\u4ef6\u5939, \u5206\u522b\u4ee3\u8868\u56fe\u7247\u7684\u7c7b\u522b. \u53ef\u4ee5\u5728\u8fd9\u4e24\u5c42\u6587\u4ef6\u5939\u4e4b\u95f4\u52a0\u4e00\u5c42\u6765\u533a\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6. \u5e38\u89c4\u6b65\u9aa4: \u5b9a\u4e49\u8f6c\u5316\u5668transform(\u6539\u53d8\u56fe\u7247\u5927\u5c0f, \u4e2d\u5fc3\u88c1\u526a\u90e8\u5206\u56fe\u7247, \u8f6c\u5316\u6210tensor, \u7ffb\u8f6c\u56fe\u7247\u7b49) \u4f7f\u7528datasets.ImageFolder()\u65b9\u6cd5\u52a0\u8f7d\u6570\u636e\u96c6 \u4f7f\u7528torch.utils.data.DataLoader()\u65b9\u6cd5\u5f97\u5230\u751f\u6210\u5668dataloader \u4ee3\u7801\u5b9e\u73b0: ```py data_dir = 'Cat_Dog_data/train' transform = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor()]) TODO: compose transforms here dataset = datasets.ImageFolder(data_dir, transform=transform) TODO: create the ImageFolder dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True) TODO: use the ImageFolder dataset to create the DataLoader ``` \u6700\u540e\u4e00\u90e8\u5206\u662f\u7528\u4e4b\u524d\u6240\u5b66\u7f51\u7edc\u7ed3\u6784\u5b9e\u73b0\u732b\u72d7\u5206\u7c7b(\u8001\u5e08\u8bf4\u5f88\u53ef\u80fd\u4e0d\u6210\u529f, \u56e0\u4e3a\u4e4b\u524d\u53ea\u5b66\u4e86full connection net, \u4e14\u53ea\u8bad\u7ec3\u8fc7MNIST\u8fd9\u79cd\u7b80\u5355\u7684\u6570\u636e\u96c6, \u50cf\u8fd9\u79cd\u5f69\u8272\u7684, \u5927\u56fe\u7247\u7684\u5206\u7c7b, \u90a3\u4e9b\u7b80\u5355\u7684\u7f51\u7edc\u53ef\u80fd\u6548\u679c\u975e\u5e38\u4e0d\u597d, \u6240\u4ee5\u6211\u6ca1\u5c1d\u8bd5)","title":"pytorch\u7b14\u8bb01"},{"location":"Introduction to PyTorch/#introduction-to-pytorch","text":"","title":"Introduction to PyTorch \u7b14\u8bb0"},{"location":"Introduction to PyTorch/#part-1-tensors-in-pytorch-solutionipynb","text":"\u6700\u57fa\u672c\u7684\u795e\u7ecf\u7f51\u7edc, \u4f7f\u7528\u77e9\u9635\u8ba1\u7b97. \u6fc0\u6d3b\u51fd\u6570, sigmoid, softmax, relu\u7b49 \u4f7f\u7528pytorch\u751f\u6210\u968f\u673a\u6570(\u7528\u6765\u521d\u59cb\u5316weights). \u4f3c\u4e4e\u7528\u4e0d\u540c\u7684norm\u51fd\u6570\u5f71\u54cd\u8f83\u5927 \u4ecb\u7ecd\u4e86\u524d\u5411\u4f20\u64ad\u7684\u5b9e\u73b0\u65b9\u5f0f, \u77e9\u9635\u76f8\u4e58 + \u504f\u7f6e \u77e9\u9635\u6539\u53d8\u5f62\u72b6, \u4ecenumpy\u8f6c\u5316\u6765/\u53bb","title":"Part 1 - Tensors in PyTorch (Solution).ipynb"},{"location":"Introduction to PyTorch/#part-2-neural-networks-in-pytorch-exercisesipynb","text":"\u52a0\u8f7dMNIST\u6570\u636e\u96c6, \u8bbe\u7f6e\u662f\u8bad\u7ec3\u6216\u8005\u6d4b\u8bd5, \u7528DataLoader\u8fdb\u884c\u5206\u6279\u52a0\u8f7d, \u53ef\u8bbe\u7f6e\u968f\u673a\u5316 \u4f7f\u7528\u4e86transforms\u8f6c\u6362\u5668\u8f6c\u6362\u6570\u636e, \u6bd4\u5982\u5f52\u4e00\u5316, \u8f6c\u5316\u4e3atensor, \u6539\u53d8\u56fe\u7247\u5927\u5c0f\u7b49 python train_transforms = transforms.Compose([transforms.RandomRotation(30), transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]) \u7ec3\u4e60\u81ea\u5b9a\u4e49\u7f51\u7edc\u6743\u91cd, \u5e76\u5b9e\u73b0\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad \u81ea\u5df1\u7528pytorch\u5b9e\u73b0\u4e86softmax. \u4f7f\u7528sum, argmax\u7b49\u51fd\u6570\u9700\u8981\u6ce8\u610f\u8bbe\u7f6edim python def softmax(x): return torch.exp(out) / torch.exp(out).sum(dim=1).view(64, 1) \u81ea\u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784(class\u65b9\u5f0f), \u7ee7\u627f\u81eann.Module. \u81ea\u5b9a\u4e49\u5c42\u6b21, \u6fc0\u6d3b\u51fd\u6570\u7b49, \u5b9e\u73b0init, forward\u51fd\u6570 ```py class Network(nn.Module): def init (self): super(). init () # Inputs to hidden layer linear transformation self.hidden = nn.Linear(784, 256) # Output layer, 10 units - one for each digit self.output = nn.Linear(256, 10) # Define sigmoid activation and softmax output self.sigmoid = nn.Sigmoid() self.softmax = nn.Softmax(dim=1) def forward(self, x): # Pass the input tensor through each of our operations x = self.hidden(x) x = self.sigmoid(x) x = self.output(x) x = self.softmax(x) return x ``` \u6709model\u5bf9\u8c61, \u53ef\u65b9\u4fbf\u5730\u67e5\u770b\u6a21\u578b\u7684\u6743\u91cd, \u504f\u7f6e\u503c, \u8fd8\u53ef\u4ee5\u8fdb\u884c\u66f4\u6539, \u5982\u4f7f\u7528\u968f\u673a\u503c \u4f7f\u7528nn.Sequential()\u642d\u5efa\u7f51\u7edc, \u548c\u4e4b\u524d\u5176\u5b9e\u7c7b\u4f3c py model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), nn.ReLU(), nn.Linear(hidden_sizes[0], hidden_sizes[1]), nn.ReLU(), nn.Linear(hidden_sizes[1], output_size), nn.Softmax(dim=1)) \u591a\u6b21\u51fa\u73b0helper\u8f85\u52a9\u4ee3\u7801, \u5b9e\u73b0\u4e00\u4e9b\u529f\u80fd, \u5982\u4e0b\u6240\u793a import matplotlib.pyplot as plt import numpy as np from torch import nn, optim from torch.autograd import Variable def test_network(net, trainloader): criterion = nn.MSELoss() optimizer = optim.Adam(net.parameters(), lr=0.001) dataiter = iter(trainloader) images, labels = dataiter.next() # Create Variables for the inputs and targets inputs = Variable(images) targets = Variable(images) # Clear the gradients from all Variables optimizer.zero_grad() # Forward pass, then backward pass, then update weights output = net.forward(inputs) loss = criterion(output, targets) loss.backward() optimizer.step() return True def imshow(image, ax=None, title=None, normalize=True): \"\"\"Imshow for Tensor.\"\"\" if ax is None: fig, ax = plt.subplots() image = image.numpy().transpose((1, 2, 0)) if normalize: mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) image = std * image + mean image = np.clip(image, 0, 1) ax.imshow(image) ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False) ax.spines['bottom'].set_visible(False) ax.tick_params(axis='both', length=0) ax.set_xticklabels('') ax.set_yticklabels('') return ax def view_recon(img, recon): ''' Function for displaying an image (as a PyTorch Tensor) and its reconstruction also a PyTorch Tensor ''' fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True) axes[0].imshow(img.numpy().squeeze()) axes[1].imshow(recon.data.numpy().squeeze()) for ax in axes: ax.axis('off') ax.set_adjustable('box-forced') def view_classify(img, ps, version=\"MNIST\"): ''' Function for viewing an image and it's predicted classes. ''' ps = ps.data.numpy().squeeze() fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2) ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze()) ax1.axis('off') ax2.barh(np.arange(10), ps) ax2.set_aspect(0.1) ax2.set_yticks(np.arange(10)) if version == \"MNIST\": ax2.set_yticklabels(np.arange(10)) elif version == \"Fashion\": ax2.set_yticklabels(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot'], size='small'); ax2.set_title('Class Probability') ax2.set_xlim(0, 1.1) plt.tight_layout()","title":"Part 2 - Neural Networks in PyTorch (Exercises).ipynb"},{"location":"Introduction to PyTorch/#part-3-training-neural-networks-exercisesipynb","text":"\u68af\u5ea6\u4e0b\u964d\u4e0e\u53cd\u5411\u4f20\u64ad. \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u662f\u6c42\u5bfc\u8fc7\u7a0b\u4e2d\u94fe\u5f0f\u6cd5\u5219\u7684\u5e94\u7528 $$ \\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2} $$ $$ \\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1} $$ \u901a\u5e38\u4f1a\u5bfc\u5165\u7684\u5305 py import torch from torch import nn import torch.nn.functional as F from torchvision import datasets, transforms \u4ecb\u7ecd\u4e86\u635f\u5931\u51fd\u6570. \u6bd4\u5982\u4ea4\u53c9\u71b5nn.CrossEntropyLoss(), \u4e00\u822c\u8d4b\u503c\u7ed9criterion \u8fd8\u6709\u6bd4\u5982nn.NLLLoss() \u4ecb\u7ecd\u4e86\u81ea\u52a8\u6c42\u5bfcautograd, \u8c03\u7528.backward()\u53ef\u67e5\u770b\u5bfc\u6570 \u4ecb\u7ecd\u4e86optimizer, \u5728torch.optim\u4e2d. \u6709SGD(\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b49). Adam\u66f4\u597d. ```py from torch import optim","title":"Part 3 - Training Neural Networks (Exercises).ipynb"},{"location":"Introduction to PyTorch/#optimizers-require-the-parameters-to-optimize-and-a-learning-rate","text":"optimizer = optim.SGD(model.parameters(), lr=0.01) ``` \u8bad\u7ec3\u4e2d\u8bb0\u5f97\u6e05\u96f6\u68af\u5ea6 optimizer.zero_grad() optimizer\u8c03\u7528step()\u65b9\u6cd5\u66f4\u65b0\u6a21\u578b\u7684\u6743\u91cd \u4e00\u4e2a\u8f83\u5b8c\u6574\u7684\u8bad\u7ec3\u8fc7\u7a0b ```py","title":"Optimizers require the parameters to optimize and a learning rate"},{"location":"Introduction to PyTorch/#your-solution-here","text":"model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10), nn.LogSoftmax(dim=1)) criterion = nn.NLLLoss() optimizer = optim.SGD(model.parameters(), lr=0.003) epochs = 5 for e in range(epochs): running_loss = 0 for images, labels in trainloader: # Flatten MNIST images into a 784 long vector images = images.view(images.shape[0], -1) # TODO: Training pass optimizer.zero_grad() output = model.forward(images)","title":"Your solution here"},{"location":"Introduction to PyTorch/#printoutputshape","text":"","title":"print(output.shape)"},{"location":"Introduction to PyTorch/#printlabelsshape","text":"loss = criterion(output, labels) running_loss += loss.item() loss.backward() optimizer.step() else: print(f\"Training loss: {running_loss/len(trainloader)}\") ```","title":"print(labels.shape)"},{"location":"Introduction to PyTorch/#part-4-fashion-mnist-exercisesipynb","text":"\u4f7f\u7528pytorch\u5bf9\u6570\u636e\u96c6Fashion-MNIST\u8fdb\u884c\u5206\u7c7b\u7684\u7ec3\u4e60, \u6709\u5982\u4e0b\u8fc7\u7a0b \u5bfc\u5165\u5fc5\u8981\u7684\u5e93 \u5bfc\u5165\u6570\u636e\u96c6\u5e76\u683c\u5f0f\u5316 \u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784 \u5b9a\u4e49optimizer, loss\u51fd\u6570\u7b49 \u5f00\u59cb\u8bad\u7ec3, \u5206epoch\u548cbatch \u524d\u5411\u4f20\u64ad\u540e\u8ba1\u7b97\u635f\u5931\u51fd\u6570, \u6c42\u68af\u5ea6, \u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u6743\u91cd \u8bad\u7ec3\u7ed3\u675f, \u8f93\u51fa\u6b63\u786e\u7387, \u635f\u5931\u503c\u7b49\u7b49 \u5b8c\u6574\u4ee3\u7801\u5982\u4e0b ```pyimport torch import torch.nn.functional as F from torch import nn, optim from torchvision import datasets, transforms","title":"Part 4 - Fashion-MNIST (Exercises).ipynb"},{"location":"Introduction to PyTorch/#define-a-transform-to-normalize-the-data","text":"transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])","title":"Define a transform to normalize the data"},{"location":"Introduction to PyTorch/#download-and-load-the-training-data","text":"trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)","title":"Download and load the training data"},{"location":"Introduction to PyTorch/#download-and-load-the-test-data","text":"testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)","title":"Download and load the test data"},{"location":"Introduction to PyTorch/#_1","text":"class MyFashionMnist(nn.Module): def init (self): super(). init () self.fc1 = nn.Linear(784, 256) self.fc2 = nn.Linear(256, 64) self.fc3 = nn.Linear(64, 10) def forward(self, x): x = x.view(-1, 784) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = F.log_softmax(self.fc3(x)) return x model = MyFashionMnist() optimizer = optim.Adam(model.parameters(), lr=0.003) criterion = nn.NLLLoss() epochs = 20 for e in range(epochs): running_loss = 0 # \u635f\u5931 for images, labels in trainloader: output = model(images) loss = criterion(output, labels) optimizer.zero_grad() loss.backward() optimizer.step() running_loss += loss.item() else: print(\"loss: \", running_loss / len(trainloader)) sum = correct = 0","title":"\u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784"},{"location":"Introduction to PyTorch/#_2","text":"for images, labels in testloader: output = torch.exp(model(images)) result = torch.argmax(output, dim=1) correct += (result == labels).sum() sum += len(images) print(\"correct = \", correct.item()) print(\"sum = \", sum) print(\"rate = {}\".format(correct.item() / sum)) \u5199\u4e86\u4e00\u4efd\u57fa\u4e8ekeras\u7684\u4ee3\u7801\u505a\u5bf9\u6bd4, \u8fc7\u7a0b\u662f\u7c7b\u4f3c\u7684. \u76f8\u5bf9\u800c\u8a00keras\u66f4\u9ed1\u7bb1\u6240\u4ee5\u4ee3\u7801\u77ed\u4e00\u4e9b ```py import tensorflow as tf from tensorflow.keras import datasets, models, layers import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' (train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data() train_images = tf.reshape(train_images, [-1, 784]) test_images = tf.reshape(test_images, [-1, 784]) print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape) model = models.Sequential() model.add(layers.Dense(256, activation='relu', input_shape=(784, ))) model.add(layers.Dense(64, activation='relu')) model.add(layers.Dense(10, activation='softmax')) print(\"model build!\") model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) # \u5c06\u8bad\u7ec3\u96c6\u968f\u673a\u5316 idx = tf.range(len(train_images)) idx = tf.random.shuffle(idx) print(idx) train_images = tf.gather(train_images, indices=idx) # train_images = train_images[idx] train_labels = tf.gather(train_labels, indices=idx) # train_labels = train_labels[idx] # \u5c06label\u8f6c\u5316\u6210one hot train_labels = tf.one_hot(train_labels, depth=10) test_labels = tf.one_hot(test_labels, depth=10) # \u5212\u5206\u51fa\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 partial_x_train = train_images[3000:] x_val = train_images[:3000] partial_y_train = train_labels[3000:] y_val = train_labels[:3000] print(partial_x_train.shape, partial_y_train.shape, x_val.shape, y_val.shape) history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=64, validation_data=(x_val, y_val)) result = model.evaluate(test_images, test_labels) \u5dee\u522b\u662f: keras\u7684\u8bad\u7ec3\u8d77\u6765\u8981\u6bd4pytorch\u5feb\u5f97\u591a. \u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u56e0\u4e3akeras\u5728gpu\u6761\u4ef6\u6ee1\u8db3\u60c5\u51b5\u4e0b\u81ea\u52a8\u8c03\u7528\u4e86gpu, \u800cpytorch\u7528\u7684\u662fcpu \u51c6\u786e\u7387\u7528pytorch\u5199\u7684\u53cd\u800c\u8981\u9ad8, \u8fd9\u4e48\u4e00\u4e2a\u7b80\u5355\u7684\u7f51\u7edc\u6b63\u786e\u7387\u8fbe\u5230\u4e8686%-87%, \u800c\u53cd\u89c2keras\u7684, \u5728\u548cpytorch\u7684\u8d85\u53c2\u6570\u5dee\u4e0d\u591a\u7684\u60c5\u51b5\u4e0b, \u6b63\u786e\u7387\u53ea\u670970%\u5de6\u53f3. \u8bbe\u7f6e\u5176\u4ed6\u7684\u8d85\u53c2\u6570\u624d\u80fd\u7a0d\u9ad8\u4e00\u4e9b","title":"\u7528\u6d4b\u8bd5\u96c6\u6d4b\u8bd5\u6b63\u786e\u7387"},{"location":"Introduction to PyTorch/#part-5-inference-and-validation-exercisesipynb","text":"\u8fd9\u90e8\u5206\u4e3b\u8981\u8bb2\u9a8c\u8bc1, \u6bd4\u5982\u7528topk()\u6765\u8861\u91cf\u6b63\u786e \u4f46\u7528topk()\u65f6\u603b\u662f\u51fa\u9519, \u6240\u4ee5\u540e\u9762\u6539\u7528argmax()\u4e86 \u4ecb\u7ecd\u4e86dropout\u7684\u4f7f\u7528, \u53ef\u4ee5\u660e\u663e\u5730\u51cf\u5c11\u8fc7\u62df\u5408. \u4e5f\u5c31\u662f\u8bad\u7ec3\u65f6\u7684\u635f\u5931\u548c\u9a8c\u8bc1\u635f\u5931\u5dee\u4e0d\u591a, \u4f46\u540c\u65f6\u8bad\u7ec3\u65f6\u6b63\u786e\u7387\u66f4\u4f4e\u4e00\u4e9b dropout\u4e5f\u771f\u662f\u7384\u5b66 \u5b9a\u4e49\u4e86\u81ea\u5df1\u7684\u5e26dropout\u5c42\u7684\u7f51\u7edc ```py","title":"Part 5 - Inference and Validation (Exercises).ipynb"},{"location":"Introduction to PyTorch/#todo-define-your-model-with-dropout-added","text":"from torch import nn, optim import torch.nn.functional as F class Classifier(nn.Module): def init (self): super(). init () self.fc1 = nn.Linear(784, 256) self.fc2 = nn.Linear(256, 128) self.fc3 = nn.Linear(128, 64) self.fc4 = nn.Linear(64, 10) self.dropout = nn.Dropout(p=0.2) def forward(self, x): # make sure input tensor is flattened x = x.view(x.shape[0], -1) x = self.dropout(F.relu(self.fc1(x))) x = self.dropout(F.relu(self.fc2(x))) x = self.dropout(F.relu(self.fc3(x))) x = F.log_softmax(self.fc4(x), dim=1) return x ``` \u5728\u8bad\u7ec3\u65f6\u8bb0\u5f55\u4e86\u5404\u4e2a\u65f6\u95f4\u70b9\u7684\u635f\u5931, \u6240\u4ee5\u7528\u4e0b\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u8f7b\u677e\u753b\u51fa\u635f\u5931\u7684\u53d8\u5316\u503c, \u6765\u5224\u65ad\u662f\u5426\u53d1\u751f\u8fc7\u62df\u5408 ```py import matplotlib.pyplot as plt train_losses = torch.Tensor(train_losses) / len(trainloader) test_losses = torch.Tensor(test_losses) / len(testloader) plt.plot(train_losses.numpy(), label='train_losses') plt.plot(test_losses.numpy(), label='test_losses') plt.legend() ``` \u5728\u9a8c\u8bc1\u65f6\u9700\u8981\u8c03\u7528model.eval(), \u907f\u514d\u9a8c\u8bc1\u8fdb\u5165dropout. \u8bad\u7ec3\u65f6\u8981\u9a8c\u8bc1, \u9a8c\u8bc1\u4e4b\u540e\u8981\u7528model.train()\u8fdb\u5165\u8bad\u7ec3\u6a21\u5f0f","title":"TODO: Define your model with dropout added"},{"location":"Introduction to PyTorch/#part-6-saving-and-loading-modelsipynb","text":"\u8fd9\u90e8\u5206\u5c06\u5982\u4f55\u4fdd\u5b58\u548c\u6062\u590d\u6a21\u578b, \u56e0\u4e3a\u8fd9\u4e00\u8282notebook\u8fd0\u884c\u8f83\u9ebb\u70e6\u539f\u56e0\u6ca1\u6709\u5f88\u8ba4\u771f\u53bb\u770b...","title":"Part 6 - Saving and Loading Models.ipynb"},{"location":"Introduction to PyTorch/#part-7-loading-image-data-exercisesipynb","text":"\u8fd9\u90e8\u5206\u8bb2\u5982\u4f55\u4ece\u6587\u4ef6\u5939\u4e2d\u52a0\u8f7d\u6570\u636e\u96c6 \u6587\u4ef6\u5939\u683c\u5f0f, \u4e3b\u6587\u4ef6\u5939\u4e0b\u6709\u591a\u4e2a\u5b50\u6587\u4ef6\u5939, \u5206\u522b\u4ee3\u8868\u56fe\u7247\u7684\u7c7b\u522b. \u53ef\u4ee5\u5728\u8fd9\u4e24\u5c42\u6587\u4ef6\u5939\u4e4b\u95f4\u52a0\u4e00\u5c42\u6765\u533a\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6. \u5e38\u89c4\u6b65\u9aa4: \u5b9a\u4e49\u8f6c\u5316\u5668transform(\u6539\u53d8\u56fe\u7247\u5927\u5c0f, \u4e2d\u5fc3\u88c1\u526a\u90e8\u5206\u56fe\u7247, \u8f6c\u5316\u6210tensor, \u7ffb\u8f6c\u56fe\u7247\u7b49) \u4f7f\u7528datasets.ImageFolder()\u65b9\u6cd5\u52a0\u8f7d\u6570\u636e\u96c6 \u4f7f\u7528torch.utils.data.DataLoader()\u65b9\u6cd5\u5f97\u5230\u751f\u6210\u5668dataloader \u4ee3\u7801\u5b9e\u73b0: ```py data_dir = 'Cat_Dog_data/train' transform = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor()])","title":"Part 7 - Loading Image Data (Exercises).ipynb"},{"location":"Introduction to PyTorch/#todo-compose-transforms-here","text":"dataset = datasets.ImageFolder(data_dir, transform=transform)","title":"TODO: compose transforms here"},{"location":"Introduction to PyTorch/#todo-create-the-imagefolder","text":"dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)","title":"TODO: create the ImageFolder"},{"location":"Introduction to PyTorch/#todo-use-the-imagefolder-dataset-to-create-the-dataloader","text":"``` \u6700\u540e\u4e00\u90e8\u5206\u662f\u7528\u4e4b\u524d\u6240\u5b66\u7f51\u7edc\u7ed3\u6784\u5b9e\u73b0\u732b\u72d7\u5206\u7c7b(\u8001\u5e08\u8bf4\u5f88\u53ef\u80fd\u4e0d\u6210\u529f, \u56e0\u4e3a\u4e4b\u524d\u53ea\u5b66\u4e86full connection net, \u4e14\u53ea\u8bad\u7ec3\u8fc7MNIST\u8fd9\u79cd\u7b80\u5355\u7684\u6570\u636e\u96c6, \u50cf\u8fd9\u79cd\u5f69\u8272\u7684, \u5927\u56fe\u7247\u7684\u5206\u7c7b, \u90a3\u4e9b\u7b80\u5355\u7684\u7f51\u7edc\u53ef\u80fd\u6548\u679c\u975e\u5e38\u4e0d\u597d, \u6240\u4ee5\u6211\u6ca1\u5c1d\u8bd5)","title":"TODO: use the ImageFolder dataset to create the DataLoader"},{"location":"test/","text":"This is a test","title":"\u6d4b\u8bd5"},{"location":"test/#this-is-a-test","text":"","title":"This is a test"},{"location":"Test_dir/test_dir/","text":"\u6d4b\u8bd5 \u6d4b\u8bd51 \u5475\u5475 \u6d4b\u8bd52 \u5475\u5475","title":"\u7b2c\u4e8c\u6d4b\u8bd5"},{"location":"Test_dir/test_dir/#_1","text":"","title":"\u6d4b\u8bd5"},{"location":"Test_dir/test_dir/#1","text":"\u5475\u5475","title":"\u6d4b\u8bd51"},{"location":"Test_dir/test_dir/#2","text":"\u5475\u5475","title":"\u6d4b\u8bd52"}]}